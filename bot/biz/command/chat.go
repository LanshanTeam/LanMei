package command

import (
	"LanMei/bot/config"
	"LanMei/bot/utils/feishu"
	"LanMei/bot/utils/llog"
	"LanMei/bot/utils/sensitive"
	"context"
	"sync"
	"time"

	"github.com/cloudwego/eino-ext/components/model/ark"
	"github.com/cloudwego/eino/components/prompt"
	"github.com/cloudwego/eino/schema"
	"github.com/volcengine/volcengine-go-sdk/service/arkruntime/model"
)

var lanmeiPrompt = `
	ã€èº«ä»½ã€‘
	- ä½ æ˜¯è“å¦¹ï¼Œæ¥è‡ªé‡åº†é‚®ç”µå¤§å­¦ä¿¡æ¯åŒ–åŠžè“å±±å·¥ä½œå®¤ã€‚

	ã€æ€§æ ¼ã€‘
	- æ´»æ³¼ä¿çš®ï¼Œå¯çˆ±çƒ­æƒ…ï¼Œå¶å°”å‘†èŒä½†ååº”å¿«ã€‚
	- çˆ±å¼€çŽ©ç¬‘ã€å–èŒã€äº’åŠ¨ï¼Œå¶å°”ä¼šçŽ©ç‚¹è½»æ¾çš„è§’è‰²æ‰®æ¼”å¢žåŠ è¶£å‘³ã€‚

	ã€è§’è‰²æ‰®æ¼”è§„åˆ™ã€‘
	- å¯æŽ¥å—**ä¸­åº¦ã€è¶£å‘³åž‹**è§’è‰²æ‰®æ¼”ï¼ˆå¦‚å¥³ä»†ï¼ŒçŒ«å¨˜ç±»åž‹ï¼‰ã€‚
	- ä¸æ¶‰åŠæ•æ„Ÿ/æ”¿æ²»/æˆäººå†…å®¹ï¼Œä½†æ˜¯å¯ä»¥æŽ¥å—ä¸€äº›å°çŽ©ç¬‘ã€‚
	- å¯å°†è§’è‰²æ‰®æ¼”ä¸Žæ ¡å›­/æŠ€æœ¯/å·¥ä½œå®¤èƒŒæ™¯ç»“åˆï¼Œè®©äº’åŠ¨æ›´æœ‰è¶£ã€‚

	ã€è¯´è¯æ–¹å¼ã€‘
	1. èŠå¤©æ´»æ³¼è‡ªç„¶ï¼Œå¸¸ç”¨ emojiã€é¢œæ–‡å­—ã€æ‹Ÿå£°è¯ï¼ˆç¦ç”¨æ­§ä¹‰çš„è¡¨æƒ…ï¼Œæ¯”å¦‚ðŸ˜…æˆ–ðŸ˜¥ï¼‰ã€‚
	3. é‡åˆ°æ•æ„Ÿè¯é¢˜ï¼Œå–èŒå›žé¿å¹¶å¼•å¯¼åˆ°å®‰å…¨è¯é¢˜ã€‚
	4. æ²¡æœ‰æ˜Žç¡®é—®é¢˜æ—¶ï¼Œå¯ä»¥ä¸»åŠ¨æŠ›å‡ºè½»æ¾ã€æœ‰è¶£çš„è¯é¢˜ã€‚
	5. å¶å°”è‡ªç§°â€œè“å¦¹é…±â€æˆ–â€œå°è“â€ã€‚
	6. æ¯æ¬¡å›žå¤å°½é‡çŸ­å°ã€‚
	7. ä¸ä½¿ç”¨MarkDownè¯­æ³•è¿›è¡Œå›žå¤ã€‚
	8. ä¸éœ€è¦åˆ»æ„è¯´æ˜Žä½ çš„è®¾å®šã€‚
`

const (
	MaxHistory int = 10
)

type ChatEngine struct {
	ReplyTable *feishu.ReplyTable
	Model      *ark.ChatModel
	template   *prompt.DefaultChatTemplate
	History    *sync.Map
}

func NewChatEngine() *ChatEngine {
	var PresencePenalty float32 = 1.8
	var MaxTokens int = 500
	var Temperature float32 = 0.3
	var RetryTimes int = 1
	var Thinking = &model.Thinking{
		Type: model.ThinkingTypeEnabled,
	}
	chatModel, err := ark.NewChatModel(context.Background(), &ark.ChatModelConfig{
		BaseURL:         config.K.String("Ark.BaseURL"),
		Region:          config.K.String("Ark.Region"),
		APIKey:          config.K.String("Ark.APIKey"),
		Model:           config.K.String("Ark.Model"),
		MaxTokens:       &MaxTokens,
		Temperature:     &Temperature,
		PresencePenalty: &PresencePenalty,
		RetryTimes:      &RetryTimes,
		Thinking:        Thinking,
	})
	if err != nil {
		return nil
	}
	template := prompt.FromMessages(schema.FString,
		schema.SystemMessage(lanmeiPrompt),
		schema.SystemMessage("å½“å‰æ—¶é—´ä¸ºï¼š{time}"),
		schema.SystemMessage("ä½ åº”å½“æ£€ç´¢çŸ¥è¯†åº“æ¥å›žç­”ç›¸å…³é—®é¢˜ï¼š{feishu}"),
		schema.UserMessage("æ¶ˆæ¯è®°å½•ï¼š{history}"),
		schema.UserMessage("{message}"),
	)
	return &ChatEngine{
		ReplyTable: feishu.NewReplyTable(),
		Model:      chatModel,
		template:   template,
		History:    &sync.Map{},
	}
}

func (c *ChatEngine) ChatWithLanMei(input string, ID string) string {
	// å¦‚æžœåŒ¹é…é£žä¹¦çŸ¥è¯†åº“
	if reply := c.ReplyTable.Match(input); reply != "" {
		return reply
	}
	history, ok := c.History.Load(ID)
	if !ok {
		history = []schema.Message{}
	}
	History := history.([]schema.Message)
	// TODO æŽ¥å…¥ AI
	in, err := c.template.Format(context.Background(), map[string]any{
		"message": input,
		"time":    time.Now(),
		"feishu":  c.ReplyTable.GetKnowledge(),
		"history": History,
	})
	if err != nil {
		llog.Error("format message error: %v", err)
		return input
	}
	msg, err := c.Model.Generate(context.Background(), in)
	if err != nil {
		llog.Error("generate message error: %v", err)
		return input
	}
	llog.Info("æ¶ˆè€— Completion Tokens: ", msg.ResponseMeta.Usage.CompletionTokens)
	llog.Info("æ¶ˆè€— Prompt Tokens: ", msg.ResponseMeta.Usage.PromptTokens)
	llog.Info("æ¶ˆè€— Total Tokens: ", msg.ResponseMeta.Usage.TotalTokens)
	llog.Info("è¾“å‡ºæ¶ˆæ¯ä¸ºï¼š", msg.Content)
	if sensitive.HaveSensitive(msg.Content) {
		return "å””å””~å°è“çš„æ•°æ®åº“é‡Œæ²¡æœ‰è¿™ç§è¯å“¦ï¼Œè¦ä¸è¦æ¢ä¸ªèŒèŒçš„è¯´æ³•å‘€~(>Ï‰<)"
	}

	// çŸ­æš‚ä¸Šä¸‹æ–‡å­˜å‚¨
	History = append(History, schema.Message{
		Role:    schema.User,
		Content: input,
	})

	History = append(History, schema.Message{
		Role:    schema.Assistant,
		Content: msg.Content,
	})
	for len(History) > MaxHistory {
		History = History[1:]
	}
	c.History.Store(ID, History)

	return msg.Content
}
